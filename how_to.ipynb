{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# first:\n",
    "- download ollama \n",
    "- run in terminal ollama serve. \n",
    "- if you don't have internet - load the models (README - and the last cell)"
   ],
   "id": "4a2d43f6deccd5b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-30T12:31:03.472847Z",
     "start_time": "2024-12-30T12:31:01.648541Z"
    }
   },
   "source": "from RIG.rule_instance_generator import RuleInstanceGenerator",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T12:31:03.723853Z",
     "start_time": "2024-12-30T12:31:03.473959Z"
    }
   },
   "cell_type": "code",
   "source": "rig = RuleInstanceGenerator()",
   "id": "a8d89b711cd268a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T12:31:04.141710Z",
     "start_time": "2024-12-30T12:31:03.724669Z"
    }
   },
   "cell_type": "code",
   "source": "rig.add_rule_types_from_folder()",
   "id": "2b721a2c32794c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Bridge.json\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "\"snowflake-arctic-embed-137m:rig\" does not support generate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResponseError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m rig\u001B[38;5;241m.\u001B[39madd_rule_types_from_folder()\n",
      "File \u001B[0;32m~/PycharmProjects/RIG_v2/RIG/rule_instance_generator.py:110\u001B[0m, in \u001B[0;36mRuleInstanceGenerator.add_rule_types_from_folder\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file_name\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 110\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnew_rule_type(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(rule_types_directory, file_name)):\n\u001B[1;32m    111\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError in add_rule_types_from_folder, loading didn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt complete. Error with: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/RIG_v2/RIG/rule_instance_generator.py:41\u001B[0m, in \u001B[0;36mRuleInstanceGenerator.new_rule_type\u001B[0;34m(self, rule_type)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnew_rule_type\u001B[39m(\u001B[38;5;28mself\u001B[39m, rule_type) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m     32\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;124;03m    Adds a new rule type to the system.\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m        bool: True if the rule type was added successfully, else False.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnew_type\u001B[38;5;241m.\u001B[39madd(rule_type)\n\u001B[1;32m     42\u001B[0m     log_interactions({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile upload\u001B[39m\u001B[38;5;124m\"\u001B[39m: rule_type})\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/RIG_v2/RIG/src/App/new_type.py:44\u001B[0m, in \u001B[0;36mNewType.add\u001B[0;34m(self, json_input)\u001B[0m\n\u001B[1;32m     42\u001B[0m default_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_default_values(rule_type)\n\u001B[1;32m     43\u001B[0m default_rule_instance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_default_rule_instance(rule_type, default_values)\n\u001B[0;32m---> 44\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_embedding(type_name, schema)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdb_manager\u001B[38;5;241m.\u001B[39mwrite_new_type(\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28mstr\u001B[39m(type_name),\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mstr\u001B[39m(schema),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28mstr\u001B[39m(embedding)\n\u001B[1;32m     54\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/RIG_v2/RIG/src/App/new_type.py:132\u001B[0m, in \u001B[0;36mNewType.create_embedding\u001B[0;34m(self, type_name, schema)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;124;03mCreate the embedding for a new rule type based on its name and schema.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m:return: The embedding as a string.\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m embedding_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrule type name: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtype_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mschema: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 132\u001B[0m embedding_json, embedding \u001B[38;5;241m=\u001B[39m MODELS\u001B[38;5;241m.\u001B[39mrag_api\u001B[38;5;241m.\u001B[39mget_embedding(\u001B[38;5;28mstr\u001B[39m(embedding_words))\n\u001B[1;32m    133\u001B[0m MODELS\u001B[38;5;241m.\u001B[39mrag_api\u001B[38;5;241m.\u001B[39madd_rule_type_embedding(type_name, embedding)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(embedding_json)\n",
      "File \u001B[0;32m~/PycharmProjects/RIG_v2/RIG/src/Utils/rag_api.py:66\u001B[0m, in \u001B[0;36mRagApi.get_embedding\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     64\u001B[0m rag_model_params \u001B[38;5;241m=\u001B[39m GLOBALS\u001B[38;5;241m.\u001B[39mrag_model_params\n\u001B[1;32m     65\u001B[0m rag_model_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m text\n\u001B[0;32m---> 66\u001B[0m embedding \u001B[38;5;241m=\u001B[39m GLOBALS\u001B[38;5;241m.\u001B[39mrag_model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrag_model_params)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     67\u001B[0m embedding_json \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mdumps(embedding[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m embedding_json, embedding\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:241\u001B[0m, in \u001B[0;36mClient.generate\u001B[0;34m(self, model, prompt, suffix, system, template, context, stream, raw, format, images, options, keep_alive)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\n\u001B[1;32m    216\u001B[0m   \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    217\u001B[0m   model: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    229\u001B[0m   keep_alive: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    230\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[GenerateResponse, Iterator[GenerateResponse]]:\n\u001B[1;32m    231\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;124;03m  Create a response using the requested model.\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m  Returns `GenerateResponse` if `stream` is `False`, otherwise returns a `GenerateResponse` generator.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 241\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    242\u001B[0m     GenerateResponse,\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/api/generate\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    245\u001B[0m     json\u001B[38;5;241m=\u001B[39mGenerateRequest(\n\u001B[1;32m    246\u001B[0m       model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    247\u001B[0m       prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m    248\u001B[0m       suffix\u001B[38;5;241m=\u001B[39msuffix,\n\u001B[1;32m    249\u001B[0m       system\u001B[38;5;241m=\u001B[39msystem,\n\u001B[1;32m    250\u001B[0m       template\u001B[38;5;241m=\u001B[39mtemplate,\n\u001B[1;32m    251\u001B[0m       context\u001B[38;5;241m=\u001B[39mcontext,\n\u001B[1;32m    252\u001B[0m       stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    253\u001B[0m       raw\u001B[38;5;241m=\u001B[39mraw,\n\u001B[1;32m    254\u001B[0m       \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mformat\u001B[39m,\n\u001B[1;32m    255\u001B[0m       images\u001B[38;5;241m=\u001B[39m[Image(value\u001B[38;5;241m=\u001B[39mimage) \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m images] \u001B[38;5;28;01mif\u001B[39;00m images \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    256\u001B[0m       options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    257\u001B[0m       keep_alive\u001B[38;5;241m=\u001B[39mkeep_alive,\n\u001B[1;32m    258\u001B[0m     )\u001B[38;5;241m.\u001B[39mmodel_dump(exclude_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m    259\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    260\u001B[0m   )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:177\u001B[0m, in \u001B[0;36mClient._request\u001B[0;34m(self, cls, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    173\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpart)\n\u001B[1;32m    175\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[0;32m--> 177\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request_raw(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\u001B[38;5;241m.\u001B[39mjson())\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:122\u001B[0m, in \u001B[0;36mClient._request_raw\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m   r\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mHTTPStatusError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 122\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mtext, e\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mstatus_code) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[0;31mResponseError\u001B[0m: \"snowflake-arctic-embed-137m:rig\" does not support generate"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T05:01:48.869498Z",
     "start_time": "2024-12-30T05:01:48.866932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get list of existing rule types:\n",
    "len(rig.get_rule_types_names())"
   ],
   "id": "40f11096719ee8f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ec20be2ba501a732"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## get rule instance from free text",
   "id": "af0758f5e833cca9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T18:06:24.747585Z",
     "start_time": "2024-12-28T18:06:17.262744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "free_text = \"An instance of ruleInstanceName - Falcon Evaluation needs to be created, dealing with the severity level two. The scavenging efficiency of this falcon is, let's say, 30. However, the beak sharpness is much sharper, let's say something like eight. The falcon's vision acuity is good, and the wing span is, um, eighty. The level of thermal riding skill is intermediate. The bone digestion efficiency is much higher, at about eighty-five. And the feather maintenance? That's excellent.\"\n",
    "\n",
    "response = rig.get_rule_instance(free_text) # return dictionary"
   ],
   "id": "d41d9ff66ad84cda",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T18:06:24.750590Z",
     "start_time": "2024-12-28T18:06:24.748438Z"
    }
   },
   "cell_type": "code",
   "source": "response.keys()",
   "id": "291f52e6d13fea73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rule_instance', 'is_error', 'error_message', 'free_text', 'type_name', 'rag_score', 'model_response', 'examples', 'schema', 'time', 'inference_time'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T18:06:24.753793Z",
     "start_time": "2024-12-28T18:06:24.751233Z"
    }
   },
   "cell_type": "code",
   "source": "response[\"rule_instance\"] # the package response",
   "id": "6dbad012ab6f1195",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '00000000-0000-0000-0000-000000000000',\n",
       " 'description': 'string',\n",
       " 'isActive': True,\n",
       " 'lastUpdateTime': '00/00/0000 00:00:00',\n",
       " 'params': {'Scavenging efficiency': 30,\n",
       "  'Flight altitude': 'null',\n",
       "  'Beak sharpness': 8,\n",
       "  'Vision acuity': 'good',\n",
       "  'Wing span': 80,\n",
       "  'Thermal riding skill': 'intermediate',\n",
       "  'Bone digestion': 85,\n",
       "  'Feather maintenance': 'excellent'},\n",
       " 'ruleInstanceName': 'falcon evaluation',\n",
       " 'severity': 2,\n",
       " 'ruleType': 'structured',\n",
       " 'ruleOwner': '',\n",
       " 'ruleTypeId': '1b5db158-d5de-47c6-90f6-25688ffece4b',\n",
       " 'eventDetails': [{'objectName': 'Vulture',\n",
       "   'objectDescription': None,\n",
       "   'timeWindowInMilliseconds': 0,\n",
       "   'useLatest': False}],\n",
       " 'additionalInformation': {},\n",
       " 'presetId': '00000000-0000-0000-0000-000000000000'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:28:14.674761Z",
     "start_time": "2024-12-16T11:28:14.672048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# giving us feedback on the response. it will help us to improve the project. it stores in .logs file, without internet connection.\n",
    "rig.feedback(rig_response=response, good=True)  # or 0.8, or what ever you can  "
   ],
   "id": "1fd6dbf5fae064c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank you :)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# now you can run the evaluation:",
   "id": "e347cadf3211cca9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T04:53:58.403652Z",
     "start_time": "2024-12-30T04:53:36.362266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rig.evaluate(\n",
    "    start_point=0,\n",
    "    end_point=2,  #  -1 or None for all the data\n",
    "    sleep_time_each_10_iter=10,\n",
    "    batch_size=800\n",
    ")"
   ],
   "id": "3a636acd65e09e7b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:21<00:00, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy Metrics:\n",
      "binary_score: 100.00%\n",
      "binary_score_no_instance_name: 100.00%\n",
      "param_numerical_binary_score: 100.00%\n",
      "param_numerical_avg_score: 100.00%\n",
      "param_verbal_binary_score: 100.00%\n",
      "param_verbal_avg_score: 100.00%\n",
      "score_rule_instance_name: 100.00%\n",
      "classification score: 100.00%\n",
      "\n",
      "Average Accuracy Metrics:\n",
      "binary_score: 100.00%\n",
      "binary_score_no_instance_name: 100.00%\n",
      "param_numerical_binary_score: 100.00%\n",
      "param_numerical_avg_score: 100.00%\n",
      "param_verbal_binary_score: 100.00%\n",
      "param_verbal_avg_score: 100.00%\n",
      "score_rule_instance_name: 100.00%\n",
      "classification score: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
